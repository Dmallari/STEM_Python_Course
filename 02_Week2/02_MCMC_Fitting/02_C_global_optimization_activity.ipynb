{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emcee corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import emcee\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleColorPlotFromFunc( \n",
    "    Func2D = None,\n",
    "    xmin = None,\n",
    "    xmax = None, \n",
    "    ymin = None,\n",
    "    ymax = None, \n",
    "    ):\n",
    "\n",
    "    #Make the list of poitns to plug in from the boundaries:\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    y = np.linspace(ymin, ymax, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    PointsToPlugIn = np.vstack([X.ravel(), Y.ravel()])\n",
    "    PointsToPlugInDataset = PointsToPlugIn.T\n",
    "\n",
    "\n",
    "    #plug in the list of points:\n",
    "    FunctionResultValuesForGrid = []\n",
    "    for Point in PointsToPlugInDataset:\n",
    "        Value = Func2D(Point)\n",
    "        FunctionResultValuesForGrid.append(Value)\n",
    "\n",
    "    #reshape stuff in a confusing way so matplotlib can think of the data like a matrix\n",
    "    Z = np.reshape(FunctionResultValuesForGrid, X.shape).T\n",
    "\n",
    "\n",
    "    #Actually construct the figure...\n",
    "    plt.figure()\n",
    "    heatmap = plt.imshow( \n",
    "        np.rot90(Z), \n",
    "        extent=[xmin, xmax, ymin, ymax] ,\n",
    "        aspect = 'auto' ,\n",
    "        interpolation = None,\n",
    "        )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Gaussian1Mean = [1,1]\n",
    "Gaussian2Mean = [2,4]\n",
    "\n",
    "Gaussian1Covariance = np.identity(2)*1\n",
    "Gaussian2Covariance = np.identity(2)*.5\n",
    "\n",
    "\n",
    "def Gaussian1(ABpoint):\n",
    "    return scipy.stats.multivariate_normal.pdf( ABpoint, mean = Gaussian1Mean, \n",
    "                                               cov = Gaussian1Covariance )\n",
    "\n",
    "def Gaussian2(ABpoint):\n",
    "    return scipy.stats.multivariate_normal.pdf( ABpoint, mean = Gaussian2Mean, \n",
    "                                               cov = Gaussian2Covariance )\n",
    "\n",
    "def GaussianMultiModal(ABpoint):\n",
    "    return Gaussian1(ABpoint) + Gaussian2(ABpoint)\n",
    "\n",
    "SimpleColorPlotFromFunc(GaussianMultiModal,\n",
    "                       xmin=-1,\n",
    "                       xmax=6,\n",
    "                       ymin=-1,\n",
    "                       ymax=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the emcee package and what you learned in the MCMC exercise to find the global peak of the joint probability density function `GaussianMultiModal`. Start with the initialized sampler below (with only 4 walkers and 125 steps per walker), but fill in a `lnprob` function that calculates the loglikelihood for a given choice of A and B. Note that in this case, the `GaussianMultiModal` function is exactly the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your lnprob function here, it could also call a lnprior function that imposes bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the MCMC to sample the full parameter space\n",
    "ndim, nwalkers = 2, 4 #number of parameters to fit (3); number of individual \"walkers\" that randomly sample the space. Choose any number, the higher the slower.\n",
    "best_guess_parameters = np.array([1,1])\n",
    "\n",
    "# This sets the starting position of each walker. It's just creating a list\n",
    "# of length nwalkers, and number of columns equal to ndim. Each row contains\n",
    "# a random location for a walker to start, based on a Gaussian\n",
    "# centered on your best guess. You can tighten or loosen this constraint by\n",
    "# changing the \"starting_location_width\" parameter. Setting it to be a very small number\n",
    "# like this is basically starting all walkers in the same location, which is the point of this \n",
    "# exercise.\n",
    "\n",
    "starting_location_width = .0001\n",
    "starting_positions = []\n",
    "for i in range(nwalkers):\n",
    "    starting_positions.append(best_guess_parameters + starting_location_width*np.random.randn(ndim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the MCMC sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, \n",
    "                                ndim, \n",
    "                                lnprob) #the likelihood function to maximize\n",
    "#run the MCMC with the starting positions we defined and 100 sampling points per walker.\n",
    "#this is the equivalent of setting the number of steps each blindfolded person can \n",
    "#take in the room, using the example above.\n",
    "n_samples_per_walker=125\n",
    "output = sampler.run_mcmc(starting_positions, n_samples_per_walker) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler.chain contains all of the samples from the MCMC.\n",
    "print(sampler.chain.shape)\n",
    "#It currently holds the samples separately for each walker.\n",
    "#We don't care about what each walker does, so let's flatten it:\n",
    "#The -1 here means we don't care how many rows it takes, \n",
    "#give us the same number of columns as we have parameters\n",
    "samples = sampler.chain.reshape((-1, ndim)) \n",
    "print(samples.shape)\n",
    "#So we tried 500 total model realizations for 3 parameters\n",
    "LogProbabilities = sampler.lnprobability.reshape((-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So what did we actually get from this? Let's use another\n",
    "#python package to see the output of the MCMC sampling.\n",
    "#The dashed line is one way of estimating the best-fit parameters\n",
    "#from an MCMC sampler (the median of the samples). The blue line\n",
    "#shows the true values.\n",
    "\n",
    "DomainBoxMinPoint=[0,-2]\n",
    "DomainBoxMaxPoint=[4,5]\n",
    "\n",
    "RangeObject = np.vstack([DomainBoxMinPoint, DomainBoxMaxPoint]).T\n",
    "fig = corner.corner(samples, #samples is defined above\n",
    "                    labels=[\"$A$\", \"$B$\"],#parameter labels\n",
    "                    truths=Gaussian2Mean,\n",
    "                    plot_contours=False,plot_density=False,\n",
    "                    plot_datapoints=True,range=RangeObject)\n",
    "\n",
    "fig = corner.corner(samples, #samples is defined above\n",
    "                    labels=[\"$A$\", \"$B$\"],#parameter labels\n",
    "                    truths=samples[LogProbabilities.argmax()],fig=fig,\n",
    "                    plot_contours=False,plot_density=False,truth_color='red',\n",
    "                    plot_datapoints=False,range=RangeObject)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_hair(x, y, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    horiz = ax.axhline(y,  **kwargs)\n",
    "    vert = ax.axvline(x, **kwargs)\n",
    "    return horiz, vert\n",
    "best_guess_peak=samples[LogProbabilities.argmax()]\n",
    "\n",
    "SimpleColorPlotFromFunc(GaussianMultiModal,\n",
    "                       xmin=-1,\n",
    "                       xmax=6,\n",
    "                       ymin=-1,\n",
    "                       ymax=6)\n",
    "cross_hair(best_guess_peak[0],best_guess_peak[1],color='red')\n",
    "print('Guess:',best_guess_peak,'Truth:',Gaussian2Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
