{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison / model selection\n",
    "## using the Akaike Information Criterion and Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages we will need in this notebook\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in some data we created for this example (.dat is a generic filename, it's just a text file)\n",
    "data_filename='https://raw.githubusercontent.com/uofscphysics/STEM_Python_Course/Summer2020/02_Week2/Data/1D_intro_examples.dat'\n",
    "example_data_1D = pandas.read_csv(data_filename,sep=',',header=0)#this file is separated by spaces and its first line contains the names of the columns (header) \n",
    "print(example_data_1D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the data, with error bars, that we read from file (See Day 2)\n",
    "plt.errorbar(example_data_1D['x'], #x,y,and error are the column names\n",
    "             example_data_1D['y'], \n",
    "             yerr=example_data_1D['error'],#yerr denotes an error in the y-direction for plotting\n",
    "             fmt='.') #fmt is \"format\", saying that I want data marked by \"points\"\n",
    "plt.xlabel('Days since I left the honey jar out') #set the x-axis label \n",
    "plt.ylabel('Number of ants') #set the y-axis label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data were generated with a simple quadratic equation:\n",
    "#ax^2+bx+c. \n",
    "\n",
    "# FILL IN :  define three models, a quadratic, cubic and exponential\n",
    "\n",
    "# def modelA_quadratic\n",
    "#    \"\"\"A quadratic in x (this happens to be the true model)\"\"\"\n",
    "\n",
    "#def modelB_cubic\n",
    "#    \"\"\"A third-order polynomial model.\"\"\"\n",
    "    \n",
    "#def modelC_exponential\n",
    "#    \"\"\"An exponential model\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Model A define a function that returns \n",
    "# the negative log likelihood:  -ln( p(Model|theta,data) )\n",
    "\n",
    "#def neg_ln_likelihoodA_quadratic(theta, args):\n",
    "#    \"\"\" This function accepts an argument \"theta\", which is \n",
    "#    a list of parameter values [alpha,beta,gamma] for model A.\n",
    "#    It then calculates a log-likelihood by computing the \n",
    "#    chi-squared statistic (i.e., assuming gaussian uncertainties), \n",
    "#    which compares the observations and errors (provided in args) \n",
    "#    to the model A.\n",
    "#    \"\"\"   \n",
    "\n",
    "# FILL IN THE FUNCTION DEFINITION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Model B\n",
    " \n",
    "# def neg_ln_likelihoodB_cubic(theta, args):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Model C\n",
    "# def neg_ln_likelihoodC_exponential(theta, args):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what these models look like, using some parameters that are in the right ball park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that plots the data (as above) and \n",
    "# all three models (given some single set of parameters for each)\n",
    "\n",
    "\n",
    "#def plot_three_models(thetaA, thetaB, thetaC):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show us a plot : \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scipy.optimize.minimize function to\n",
    "# do a maximum likelihood estimation \n",
    "# (equivalent to chi2 minimization) \n",
    "# to find the best parameters for each model\n",
    "\n",
    "# FILL IN THE ARGUMENTS TO EACH CALL OF MINIMIZE()\n",
    "\n",
    "# maxlike_resultA = scipy.optimize.minimize( )\n",
    "\n",
    "# maxlike_resultB = scipy.optimize.minimize( )\n",
    "\n",
    "# maxlike_resultC = scipy.optimize.minimize( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results (the minimum ln(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plotting function defined above to show \n",
    "# a plot of the three models with their 'best-fit' parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison :  the AIC and BIC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Akaike information criterion is defined as:\n",
    "\n",
    "### AIC = 2 k - 2 ln(L)\n",
    "\n",
    "it balances a model's ability to fit the data (measured by the maximum likelihood value L) against the number of parameters 'k' that the model requires.  A smaller value of the AIC indicates a better model (i.e., one that matches the data well, without being unnecessarily complex).\n",
    "\n",
    "The Bayesian information criterion is very similar. It replaces the 2 in the first term with ln(n), where n is the number of data points.  This puts more weight on the first term (which penalizes complexity) when the size of the sample is large.  As with the AIC, smaller is better.\n",
    "\n",
    "### BIC = k ln( n ) - 2 ln( L )\n",
    "\n",
    "These two metrics are the most commonly used, but many others exist, with subtle differences in their properties.  One should take care to apply the appropriate criteria based on the data, the models, and the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define a function that computes the AIC and BIC for each of our three models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute each max likelihood value and report.  \n",
    "\n",
    "# Remember that we have found the minimum\n",
    "# of the negative log likelihood for each\n",
    "# function. This is reported as the 'fun'\n",
    "# entry in our set of results from the \n",
    "# scipy.optimize.minimize() function calls.\n",
    "\n",
    "# The opposite of that minimum is our maximum log likelihood.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the AIC and BIC for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect them into 3-element lists for convenience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a nice pandas DataFrame table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the AIC and BIC Weights :  e^(-0.5*deltaAIC)\n",
    "\n",
    "\n",
    "# Compute the AIC / BIC odds ratios :  weight_max / weight_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the updated pandas table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next topic :  using the Bayesian evidence (Bayes factors) to compare models considering the entire parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading list\n",
    "\n",
    "A good broad book on Bayesian data analysis\n",
    "* Sivia, D. and Skilling, J. \"Data Analysis: A Bayesian Tutorial\"\n",
    "https://books.google.com/books/about/Data_Analysis.html?id=lYMSDAAAQBAJ\n",
    "\n",
    "Some summary papers: \n",
    "\n",
    "* Wagenmakers and Farrell 2004\n",
    "https://link.springer.com/content/pdf/10.3758/BF03206482.pdf\n",
    "\n",
    "* Symonds and Moussalli 2010\n",
    "http://byrneslab.net/classes/biol607/readings/Symonds_and_Moussalli_2010_behav_ecol.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
